{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data input\n",
    "csvname = datapath + 'breast_cancer_data.csv'\n",
    "data1 = np.loadtxt(csvname,delimiter = ',')\n",
    "\n",
    "# get input and output of dataset\n",
    "x = data1[:-1,:]\n",
    "y = data1[-1:,:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute linear combination of input points\n",
    "def model(x,w):\n",
    "    a = w[0] + np.dot(x.T,w[1:])\n",
    "    return a.T\n",
    "\n",
    "# an implementation of the softmax cost\n",
    "def softmax(w):    \n",
    "    # compute the least squares cost\n",
    "    cost = np.sum(np.log(1 + np.exp(-y*model(x,w))))\n",
    "    return cost/float(np.size(y))\n",
    "\n",
    "# an implementation of the perceptron cost\n",
    "def perceptron(w):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_its = 1000\n",
    "w = 0.1*np.random.randn(9,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### miscounts ###\n",
    "def miscount(w,x,y):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miscount_history = [miscount(v,x,y) for v in weight_history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.argwhere(y>0.9)\n",
    "b=np.argwhere(y<-0.9)\n",
    "yc=np.arange(699)\n",
    "yc[a]=1\n",
    "yc[b]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sigmoid function\n",
    "def sigmoid(t):\n",
    "    return 1/(1 + np.exp(-t))\n",
    "\n",
    "# the convex cross-entropy cost function\n",
    "lam = 2*10**(-3)\n",
    "def cross_entropy(w):\n",
    "    # compute sigmoid of model\n",
    "    a = sigmoid(model(x,w))\n",
    "\n",
    "    # compute cost of label 0 points\n",
    "    ind = np.argwhere(yc == 0)\n",
    "    cost = -np.sum(np.log(1 - a[:,ind]))\n",
    "\n",
    "    # add cost on label 1 points\n",
    "    ind = np.argwhere(yc==1)\n",
    "    cost -= np.sum(np.log(a[:,ind]))\n",
    "\n",
    "    # add regularizer\n",
    "    cost += lam*np.sum(w[1:]**2)\n",
    "\n",
    "    # compute cross-entropy\n",
    "    return cost/float(np.size(yc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard normalization function - with nan checker / filler in-er\n",
    "def standard_normalizer(x):    \n",
    "    # compute the mean and standard deviation of the input\n",
    "    x_means = np.nanmean(x,axis = 1)[:,np.newaxis]\n",
    "    x_stds = np.nanstd(x,axis = 1)[:,np.newaxis]   \n",
    "\n",
    "    # check to make sure that x_stds > small threshold, for those not\n",
    "    # divide by 1 instead of original standard deviation\n",
    "    ind = np.argwhere(x_stds < 10**(-2))\n",
    "    if len(ind) > 0:\n",
    "        ind = [v[0] for v in ind] # Just keep the row index\n",
    "        adjust = np.zeros((x_stds.shape))\n",
    "        adjust[ind] = 1.0\n",
    "        x_stds += adjust\n",
    "\n",
    "    # fill in any nan values with means \n",
    "    ind = np.argwhere(np.isnan(x) == True)\n",
    "    for i in ind:\n",
    "        x[i[0],i[1]] = x_means[i[0]]\n",
    "\n",
    "    # create standard normalizer function\n",
    "    normalizer = lambda data: (data - x_means)/x_stds\n",
    "\n",
    "    # create inverse standard normalizer\n",
    "    inverse_normalizer = lambda data: data*x_stds + x_means\n",
    "\n",
    "    # return normalizer \n",
    "    return normalizer,inverse_normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data input\n",
    "csvname = datapath + 'spambase_data.csv'\n",
    "data = np.loadtxt(csvname,delimiter = ',')\n",
    "\n",
    "# get input and output of dataset\n",
    "x = data[:-1,:]\n",
    "y = data[-1:,:] \n",
    "normalizer,inverse_normalizer = standard_normalizer(x)\n",
    "x = normalizer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in dataset\n",
    "csvname = datapath + 'credit_dataset.csv'\n",
    "data = np.loadtxt(csvname,delimiter = ',')\n",
    "x = data[:-1,:]\n",
    "y = data[-1:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute C linear combinations of input point, one per classifier\n",
    "def model(x,w):\n",
    "    a = w[0] + np.dot(x.T,w[1:])\n",
    "    return a.T\n",
    "\n",
    "lam = 10**-5  # our regularization paramter \n",
    "def multiclass_perceptron(w):        \n",
    "    # pre-compute predictions on all points\n",
    "    all_evals = model(x,w)\n",
    "    \n",
    "    # compute maximum across data points\n",
    "    a = np.max(all_evals,axis = 0)    \n",
    "\n",
    "    # compute cost in compact form using numpy broadcasting\n",
    "    b = all_evals[y.astype(int).flatten(),np.arange(np.size(y))]\n",
    "    cost = np.sum(a - b)\n",
    "    \n",
    "    # add regularizer\n",
    "    cost = cost + lam*np.linalg.norm(w[1:,:],'fro')**2\n",
    "    \n",
    "    # return average\n",
    "    return cost/float(np.size(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in dataset\n",
    "data = np.loadtxt(datapath + '3class_data.csv',delimiter = ',')\n",
    "\n",
    "# get input/output pairs\n",
    "x = data[:-1,:]\n",
    "y = data[-1:,:] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
